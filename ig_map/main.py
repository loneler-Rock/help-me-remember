import os
import sys
import time
import re
import requests
import json
from supabase import create_client, Client
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from urllib.parse import unquote
from selenium.webdriver.common.by import By

# --- 1. åˆå§‹åŒ–è¨­å®š ---
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_ROLE_KEY")
LINE_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")

try:
    if not SUPABASE_URL or not SUPABASE_KEY:
        raise ValueError("ç¼ºå°‘ SUPABASE_URL æˆ– SUPABASE_KEY")
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    print(f"âŒ Supabase åˆå§‹åŒ–å¤±æ•—: {e}")
    sys.exit(1)

def reply_line(token, messages):
    if not token:
        print("âš ï¸ [DEBUG] æ²’æœ‰ Reply Tokenï¼Œç•¥éå›è¦†")
        return
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {LINE_TOKEN}"}
    try:
        requests.post("https://api.line.me/v2/bot/message/reply", headers=headers, json={"replyToken": token, "messages": messages})
    except Exception as e:
        print(f"âŒ LINE å›è¦†å¤±æ•—: {e}")

# --- 2. è¼”åŠ©å·¥å…·ï¼šé‡è¤‡æª¢æŸ¥èˆ‡ OSM ---

def check_duplicate(user_id, location_name):
    """æª¢æŸ¥è³‡æ–™åº«æ˜¯å¦å·²æœ‰ç›¸åŒåº—å"""
    try:
        # æœå°‹è©²ä½¿ç”¨è€…æ˜¯å¦å­˜éå®Œå…¨ä¸€æ¨£çš„åº—å
        response = supabase.table("map_spots").select("*").eq("user_id", user_id).eq("location_name", location_name).execute()
        if response.data and len(response.data) > 0:
            return response.data[0] # å›å‚³å·²å­˜åœ¨çš„è³‡æ–™
        return None
    except Exception as e:
        print(f"âš ï¸ æª¢æŸ¥é‡è¤‡å¤±æ•—: {e}")
        return None

def parse_osm_category(data):
    if not data: return None
    if isinstance(data, list):
        if not data: return None
        item = data[0]
    else:
        item = data

    osm_category = item.get('category', '') or item.get('class', '')
    osm_type = item.get('type', '')
    if not osm_category and 'addresstype' in item:
        osm_category = item['addresstype']

    print(f"   â†³ OSM å±¬æ€§åˆ†æ: Class={osm_category}, Type={osm_type}")

    food_types = ['restaurant', 'cafe', 'fast_food', 'food_court', 'bar', 'pub', 'ice_cream', 'biergarten', 'deli']
    if osm_category == 'amenity' and osm_type in food_types: return "ç¾é£Ÿ"
    if osm_category == 'shop' and osm_type in ['food', 'bakery', 'pastry', 'beverage', 'coffee', 'tea', 'deli']: return "ç¾é£Ÿ"
    
    sight_types = ['attraction', 'museum', 'viewpoint', 'artwork', 'gallery', 'zoo', 'theme_park', 'park', 'castle']
    if osm_category in ['tourism', 'historic', 'leisure', 'natural']: return "æ™¯é»"
    
    # OSM çš„ä½å®¿åˆ¤å®š
    if osm_category == 'tourism' and osm_type in ['hotel', 'hostel', 'guest_house', 'motel', 'apartment']: return "ä½å®¿"
    
    return None

def get_osm_by_coordinate(lat, lng):
    try:
        url = f"https://nominatim.openstreetmap.org/reverse?format=json&lat={lat}&lon={lng}&zoom=18&addressdetails=1&accept-language=zh-TW"
        headers = {'User-Agent': 'HelpMeRememberBot/2.7'}
        r = requests.get(url, headers=headers, timeout=5)
        return parse_osm_category(r.json())
    except:
        return None

def get_osm_by_name(name, lat, lng):
    try:
        viewbox = f"{lng-0.002},{lat-0.002},{lng+0.002},{lat+0.002}"
        print(f"ğŸ•µï¸ [DEBUG] å•Ÿå‹• OSM å§“ååµæ¢: æœå°‹ '{name}'...")
        url = f"https://nominatim.openstreetmap.org/search?q={name}&format=json&viewbox={viewbox}&bounded=1&limit=1&accept-language=zh-TW"
        headers = {'User-Agent': 'HelpMeRememberBot/2.7'}
        r = requests.get(url, headers=headers, timeout=5)
        data = r.json()
        if data:
            print("   âœ… OSM å§“åæœå°‹å‘½ä¸­ï¼")
            return parse_osm_category(data)
        return None
    except:
        return None

def determine_category_smart(title, full_text, lat, lng):
    """V2.7 åˆ†é¡ï¼šæ–°å¢ä½å®¿é—œéµå­—"""
    
    print(f"ğŸ•µï¸ [DEBUG] å•Ÿå‹•é—œéµå­—æƒæ (å…¨æ–‡é•·åº¦: {len(full_text)} å­—)...")
    
    # é—œéµå­—åº«
    food_keywords = ["é¤å»³", "å’–å•¡", "Coffee", "Cafe", "éºµ", "é£¯", "é£Ÿ", "å‘³", "é¤é…’é¤¨", "Bar", "ç”œé»", "ç«é‹", "æ–™ç†", "Bistro", "æ—©åˆé¤", "ç‰›æ’", "å£½å¸", "ç‡’è‚‰", "å°åƒ", "æ—©é¤", "åˆé¤", "æ™šé¤", "é£Ÿå ‚", "Tea", "é£²", "å†°", "æ»·å‘³", "è±†èŠ±", "ç‚¸é›", "çƒ˜ç„™", "å±…é…’å±‹", "æ‹‰éºµ", "ä¸¼", "ç´ é£Ÿ", "ç†Ÿé£Ÿ", "æ”¤", "åº—", "èˆ–", "é¤¨", "èœ", "è‚‰", "æ¹¯"]
    travel_keywords = ["è»Šç«™", "å…¬åœ’", "å±±", "æµ·", "å¯º", "å»Ÿ", "åšç‰©é¤¨", "æ­¥é“", "è¾²å ´", "æ¨‚åœ’", "å±•è¦½", "View", "æ™¯é»", "æ–‡å‰µ", "æ­¥é“", "å­¸æ ¡", "ä¸­å¿ƒ", "è¨ºæ‰€", "é†«é™¢", "æ•™æœƒ", "å®®", "æ®¿", "å¤è¹Ÿ", "è€è¡—", "å¤œå¸‚", "é¢¨æ™¯"]
    lodging_keywords = ["Hotel", "æ°‘å®¿", "é£¯åº—", "æ—…é¤¨", "é…’åº—", "å®¢æ£§", "æ—…åº—", "è¡Œé¤¨", "Resort", "ä½å®¿", "æœƒé¤¨"]

    scan_text = (title + " " + full_text[:1000]).replace("\n", " ")
    
    # 1. é—œéµå­—æƒæ
    for kw in food_keywords:
        if kw in scan_text: return "ç¾é£Ÿ"
    for kw in lodging_keywords:
        if kw in scan_text: return "ä½å®¿"
    for kw in travel_keywords:
        if kw in scan_text: return "æ™¯é»"

    # 2. OSM åå­—åµæ¢
    if title and title != "æœªå‘½ååœ°é»":
        cat = get_osm_by_name(title, lat, lng)
        if cat: return cat

    # 3. OSM åº§æ¨™åµæ¢
    cat = get_osm_by_coordinate(lat, lng)
    if cat: return cat
        
    return "å…¶å®ƒ"

# --- 3. ç€è¦½å™¨çˆ¬èŸ² ---

def get_real_url_with_browser(url):
    print(f"ğŸ•µï¸ [DEBUG] å•Ÿå‹• Chrome (V2.7)... ç›®æ¨™: {url}")
    
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_experimental_option('prefs', {'intl.accept_languages': 'zh-TW,zh;q=0.9,en;q=0.8'})
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")

    driver = None
    final_url = url
    page_title = ""
    page_text = ""
    
    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        
        # å½é€  GPS (å°åŒ—)
        params = {"latitude": 25.033964, "longitude": 121.564468, "accuracy": 100}
        driver.execute_cdp_cmd("Emulation.setGeolocationOverride", params)

        if "?" in url: target_url = url + "&hl=zh-TW&gl=TW"
        else: target_url = url + "?hl=zh-TW&gl=TW"
            
        driver.get(target_url)
        print("   â³ ç­‰å¾…é é¢è¼‰å…¥ (6ç§’)...")
        time.sleep(6)
        
        final_url = driver.current_url
        page_title = driver.title
        try:
            body_element = driver.find_element(By.TAG_NAME, "body")
            page_text = body_element.text
        except:
            page_text = ""
                
        print(f"   âœ… æ¨™é¡Œ: {page_title}")
        
    except Exception as e:
        print(f"âš ï¸ [DEBUG] ç€è¦½å™¨åŸ·è¡ŒéŒ¯èª¤: {e}")
    finally:
        if driver: driver.quit()
            
    return final_url, page_title, page_text

# --- 4. ä¸»æµç¨‹ ---

def extract_map_url(text):
    if not text: return None
    match = re.search(r'(https?://[^\s]*(?:google|goo\.gl|maps\.app\.goo\.gl)[^\s]*)', text)
    return match.group(1) if match else None

def parse_coordinates(url):
    if not url: return None, None
    url = unquote(url)
    match = re.search(r'@(-?\d+\.\d+),(-?\d+\.\d+)', url)
    if match: return float(match.group(1)), float(match.group(2))
    match = re.search(r'search/(-?\d+\.\d+),(-?\d+\.\d+)', url)
    if match: return float(match.group(1)), float(match.group(2))
    match_lat = re.search(r'!3d(-?\d+\.\d+)', url)
    match_lng = re.search(r'!4d(-?\d+\.\d+)', url)
    if match_lat and match_lng: return float(match_lat.group(1)), float(match_lng.group(2))
    return None, None

def handle_save_task(raw_message, user_id, reply_token):
    print(f"ğŸ“¥ [å­˜æª”æ¨¡å¼] é–‹å§‹è™•ç†...")
    
    target_url = extract_map_url(raw_message)
    if not target_url and ("google" in raw_message or "goo.gl" in raw_message) and "http" in raw_message:
         target_url = raw_message.strip()

    if not target_url:
        print("âš ï¸ [DEBUG] éåœ°åœ–é€£çµ")
        reply_line(reply_token, [{"type": "text", "text": "ğŸ“ å·²å­˜ç‚ºç´”æ–‡å­—ç­†è¨˜ã€‚"}])
        return

    # 1. çˆ¬èŸ²
    final_url, page_title, page_text = get_real_url_with_browser(target_url)
    
    # 2. è§£æ
    lat, lng = parse_coordinates(final_url)
    final_title = page_title.replace(" - Google åœ°åœ–", "").replace(" - Google Maps", "").strip()
    if final_title == "Google Maps": final_title = "æœªå‘½ååœ°é»"

    # 3. åˆ†é¡
    category = determine_category_smart(final_title, page_text, lat, lng)

    print(f"ğŸ•µï¸ [DEBUG] æº–å‚™å­˜æª” -> åº—å: {final_title} | é¡åˆ¥: {category}")

    if lat and lng:
        # â˜…â˜…â˜… V2.7 æ–°åŠŸèƒ½ï¼šæª¢æŸ¥æ˜¯å¦é‡è¤‡ â˜…â˜…â˜…
        existing_spot = check_duplicate(user_id, final_title)
        
        if existing_spot:
            # å¦‚æœå·²ç¶“å­˜åœ¨ï¼Œå°±ä¸å­˜äº†ï¼Œç›´æ¥å›è¦†
            print(f"âš ï¸ [DEBUG] ç™¼ç¾é‡è¤‡è³‡æ–™ï¼Œè·³éå¯«å…¥ã€‚")
            msg = f"ğŸ˜… é€™å®¶åº—ä½ å­˜éå›‰ï¼\nåº—å: {final_title}\nåˆ†é¡: {existing_spot.get('category', category)}"
            reply_line(reply_token, [{"type": "text", "text": msg}])
            return

        # ä¸é‡è¤‡æ‰å¯«å…¥
        data = {
            "user_id": user_id,
            "location_name": final_title,
            "google_map_url": final_url,
            "address": final_url,
            "latitude": lat,
            "longitude": lng,
            "category": category,
            "geom": f"POINT({lng} {lat})",
            "created_at": "now()"
        }
        try:
            supabase.table("map_spots").insert(data).execute()
            print(f"âœ… æˆåŠŸå¯«å…¥è³‡æ–™åº«")
            reply_line(reply_token, [{"type": "text", "text": f"âœ… å·²æ”¶è—ï¼\nåº—å: {final_title}\nåˆ†é¡: {category}"}])
        except Exception as
