import os
import sys
import re
import time
import json
import base64  # âœ… é—œéµå·¥å…·: æ‹†åŒ…å™¨
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
from supabase import create_client, Client

# --- 1. åˆå§‹åŒ– ---
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_ROLE_KEY")

try:
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âš ï¸ è­¦å‘Š: æœªåµæ¸¬åˆ° Supabase ç’°å¢ƒè®Šæ•¸")
        supabase = None
    else:
        supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    print(f"âŒ Supabase åˆå§‹åŒ–å¤±æ•—: {e}")
    sys.exit(1)

# --- 2. å·¥å…·å‡½å¼ ---

def decode_base64_safe(data):
    """
    ã€V10.8 æ–°åŠŸèƒ½ã€‘è‡ªå‹•æ‹†åŒ… Base64
    """
    if not data: return ""
    try:
        # å˜—è©¦è§£ç¢¼ (Make å‚³éä¾†çš„æ˜¯ Base64 ç·¨ç¢¼çš„äº‚ç¢¼)
        decoded = base64.b64decode(data).decode('utf-8')
        return decoded
    except:
        # å¦‚æœä¸æ˜¯ Base64 (ä¾‹å¦‚æ‰‹å‹•æ¸¬è©¦å‚³ç´”æ–‡å­—)ï¼Œç›´æ¥å›å‚³åŸå­—ä¸²
        return data

def extract_url_from_text(text):
    """å¾é›œäº‚æ–‡å­—ä¸­æŠ“å‡ºç¶²å€"""
    if not text: return None
    
    # â˜… ç¬¬ä¸€æ­¥ï¼šå…ˆæ‹†åŒ…
    decoded_text = decode_base64_safe(text)
    print(f"ğŸ“¦ è§£ç¢¼å¾Œå…§å®¹: {decoded_text}") 
    
    # â˜… ç¬¬äºŒæ­¥ï¼šæŠ“ç¶²å€
    match = re.search(r'(https?://[^\s]+)', decoded_text)
    if match: return match.group(1)
    return decoded_text

def clean_price_text(text):
    if not text: return None
    clean = re.sub(r'[^\d]', '', str(text))
    return int(clean) if clean else None

def extract_json_ld(soup, platform):
    scripts = soup.find_all('script', type='application/ld+json')
    for script in scripts:
        try:
            data = json.loads(script.string)
            if isinstance(data, list):
                for item in data:
                    if item.get('@type') == 'Product': return item
            elif isinstance(data, dict):
                if data.get('@type') == 'Product': return data
        except: continue
    return None

# --- 3. è§£æé‚è¼¯ ---

def parse_momo(soup):
    price, title = None, "Momoå•†å“"
    
    # JSON-LD
    json_data = extract_json_ld(soup, "momo")
    if json_data:
        if 'offers' in json_data and 'price' in json_data['offers']:
            price = clean_price_text(json_data['offers']['price'])
        if 'name' in json_data:
