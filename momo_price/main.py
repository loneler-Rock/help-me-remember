import os
import sys
import re
import time
import json
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
from supabase import create_client, Client

# --- 1. åˆå§‹åŒ–ç’°å¢ƒè®Šæ•¸èˆ‡è³‡æ–™åº« ---
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_ROLE_KEY")

try:
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âš ï¸ è­¦å‘Š: æœªåµæ¸¬åˆ° Supabase ç’°å¢ƒè®Šæ•¸ (è‹¥åœ¨æœ¬æ©Ÿæ¸¬è©¦è«‹å¿½ç•¥)")
        supabase = None
    else:
        supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    print(f"âŒ Supabase åˆå§‹åŒ–å¤±æ•—: {e}")
    sys.exit(1)

# --- 2. å·¥å…·å‡½å¼ ---

def clean_price_text(text):
    """æ¸…é™¤ $ , å…ƒ ç­‰é›œè¨Šï¼Œåªç•™æ•¸å­—"""
    if not text: return None
    # è½‰æˆå­—ä¸²ä¸¦ç§»é™¤æ‰€æœ‰éæ•¸å­—å­—ç¬¦
    clean = re.sub(r'[^\d]', '', str(text))
    return int(clean) if clean else None

def extract_json_ld(soup, platform):
    """
    ã€é«˜éšæŠ€å·§ã€‘å¾ SEO çµæ§‹åŒ–è³‡æ–™ä¸­æå–åƒ¹æ ¼
    é€™æ˜¯æœ€ç©©å®šçš„æ–¹æ³•ï¼Œå› ç‚ºç¶²ç«™å¾ˆå°‘æ”¹å‹•çµ¦ Google çœ‹çš„è³‡æ–™
    """
    scripts = soup.find_all('script', type='application/ld+json')
    for script in scripts:
        try:
            data = json.loads(script.string)
            
            # PChome çš„çµæ§‹é€šå¸¸æ˜¯ä¸€å€‹åˆ—è¡¨ï¼Œæˆ–è€…å–®ä¸€ç‰©ä»¶
            if isinstance(data, list):
                for item in data:
                    if item.get('@type') == 'Product':
                        return item
            elif isinstance(data, dict):
                if data.get('@type') == 'Product':
                    return data
        except:
            continue
    return None

# --- 3. å¹³å°è§£æé‚è¼¯ ---

def parse_momo(soup):
    """Momo è§£æé‚è¼¯ (æ··åˆæ¨¡å¼)"""
    price = None
    title = "Momoå•†å“"

    # 1. å˜—è©¦ JSON-LD (Momo æœ‰æ™‚å€™æœ‰)
    json_data = extract_json_ld(soup, "momo")
    if json_data:
        if 'offers' in json_data and 'price' in json_data['offers']:
            price = clean_price_text(json_data['offers']['price'])
        if 'name' in json_data:
            title = json_data['name']

    # 2. å¦‚æœ JSON-LD æ²’æŠ“åˆ°ï¼Œä½¿ç”¨å‚³çµ± CSS Selector
    if not price:
        price_tag = soup.find('span', {'class': 'price'})
        if not price_tag: price_tag = soup.find('span', {'class': 'seoPrice'})
        if not price_tag:
            price_element = soup.select_one("ul.price li.special span.price b")
            if price_element: price_tag = price_element
        
        if price_tag:
            price = clean_price_text(price_tag.text)

    # 3. æ¨™é¡Œå¾Œè£œ
    if title == "Momoå•†å“":
        og_title = soup.find("meta", property="og:title")
        if og_title: title = og_title["content"]
        else:
            page_title = soup.find("title")
            if page_title: title = page_title.text.split("- momo")[0].strip()

    return price, title

def parse_pchome(soup):
    """PChome è§£æé‚è¼¯ (JSON-LD å„ªå…ˆ)"""
    price = None
    title = "PChomeå•†å“"

    # --- ç­–ç•¥ A: JSON-LD (æœ€å¼·å¤§) ---
    # PChome å¹¾ä¹ä¸€å®šæœ‰é€™å€‹ï¼Œä¸”åŒ…å«äº†ç²¾ç¢ºåƒ¹æ ¼
    json_data = extract_json_ld(soup, "pchome")
    if json_data:
        # print(f"DEBUG: æ‰¾åˆ° JSON-LD è³‡æ–™") # é™¤éŒ¯ç”¨
        if 'offers' in json_data:
            offers = json_data['offers']
            # PChome çš„ offers æœ‰æ™‚æ˜¯ list æœ‰æ™‚æ˜¯ dict
            if isinstance(offers, dict) and 'price' in offers:
                price = clean_price_text(offers['price'])
            elif isinstance(offers, list) and len(offers) > 0 and 'price' in offers[0]:
                price = clean_price_text(offers[0]['price'])
        
        if 'name' in json_data:
            title = json_data['name']
            
        if price: return price, title

    # --- ç­–ç•¥ B: Meta Tags (æ¬¡è¦ç©©å®š) ---
    if not price:
        meta_price = soup.find("meta", property="product:price:amount")
        if not meta_price: meta_price = soup.find("meta", property="og:price:amount")
        
        if meta_price:
            price = clean_price_text(meta_price["content"])

    # --- ç­–ç•¥ C: æš´åŠ›è¦–è¦ºæœå°‹ (æœ€å¾Œæ‰‹æ®µ) ---
    if not price:
        # PChome çš„åƒ¹æ ¼å€å¡Šç¶“å¸¸è®Šå‹•ï¼Œé€™è£¡åˆ—å‡ºå¹¾ç¨®å¸¸è¦‹çš„
        selectors = [
            "#PriceTotal", 
            ".o-prodPrice__price", 
            ".price-info__price",
            "span[id^='PriceTotal']"
        ]
        for sel in selectors:
            tag = soup.select_one(sel)
            if tag:
                price = clean_price_text(tag.text)
                if price: break

    # è£œæŠ“æ¨™é¡Œ
    if title == "PChomeå•†å“":
        name_tag = soup.find(id="NickName")
        if name_tag: title = name_tag.text.strip()
        else:
            page_title = soup.find("title")
            if page_title: title = page_title.text.split("- PChome")[0].strip()

    return price, title

def get_product_info(url):
    print(f"ğŸ” æ­£åœ¨è§£æ: {url}...")
    
    platform = "unknown"
    if "momoshop.com.tw" in url:
        platform = "momo"
        print("ğŸ’¡ è­˜åˆ¥ç‚º: Momo è³¼ç‰©ç¶²")
    elif "pchome.com.tw" in url:
        platform = "pchome"
        print("ğŸ’¡ è­˜åˆ¥ç‚º: PChome 24h")

    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    # éš¨æ©Ÿ User Agent é¿å…è¢«æ“‹
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")

    driver = webdriver.Chrome(options=chrome_options)
    
    try:
        driver.get(url)
        time.sleep(5) # ç­‰å¾… PChome çš„ JS è·‘å®Œ
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        if platform == "momo":
            return parse_momo(soup)
        elif platform == "pchome":
            return parse_pchome(soup)
        else:
            return parse_momo(soup)

    except Exception as e:
        print(f"âŒ çˆ¬èŸ²ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None, None
    finally:
        driver.quit()

# --- 4. è³‡æ–™åº«å„²å­˜ ---

def save_price_record(user_id, url, price, title):
    if not supabase:
        print("âš ï¸ ç„¡æ³•é€£ç·šè³‡æ–™åº«ï¼Œè·³éå„²å­˜")
        return

    print(f"ğŸ’¾ æ­£åœ¨å„²å­˜: {title} | ${price}")
    
    try:
        product_data = {
            "user_id": user_id,
            "original_url": url,
            "current_price": price,
            "product_name": title,
            "is_active": True,
            "updated_at": "now()"
        }
        
        existing = supabase.table("products").select("id").eq("original_url", url).eq("user_id", user_id).execute()
        
        product_id = None
        if existing.data:
            product_id = existing.data[0]['id']
            supabase.table("products").update(product_data).eq("id", product_id).execute()
        else:
            result = supabase.table("products").insert(product_data).execute()
            if result.data:
                product_id = result.data[0]['id']

        if product_id:
            history_data = {
                "product_id": product_id,
                "price": price,
                "recorded_at": "now()"
            }
            supabase.table("price_history").insert(history_data).execute()
            print("âœ… åƒ¹æ ¼æ­·å²å·²è¨˜éŒ„")

    except Exception as e:
        print(f"âŒ è³‡æ–™åº«å¯«å…¥å¤±æ•—: {e}")

if __name__ == "__main__":
    if len(sys.argv) > 2:
        target_url = sys.argv[1]
        user_id = sys.argv[2]
        
        print("ğŸš€ å•Ÿå‹• V10.6 çµæ§‹åŒ–æ•¸æ“šç‰ˆ...")
        
        current_price, product_title = get_product_info(target_url)
        
        if current_price:
            print(f"ğŸ’° æˆåŠŸæŠ“å–åƒ¹æ ¼: {current_price}")
            save_price_record(user_id, target_url, current_price, product_title)
        else:
            print(f"âŒ è§£æå¤±æ•—: PChome çµæ§‹è®Šæ›´ï¼Œè«‹æª¢æŸ¥ JSON-LD æ ¼å¼ã€‚")
    else:
        print("âŒ åƒæ•¸ä¸è¶³")
